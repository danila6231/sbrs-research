/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/ray/_private/parameter.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
05 Jun 21:06    INFO  ['run_base.py', '--MAX_ITEM_LIST_LENGTH=50']
05 Jun 21:06    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = dataset/ml-1m
checkpoint_dir = saved
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni100', 'test': 'uni100'}}
repeatable = True
metrics = ['NDCG', 'MRR', 'Hit']
topk = [10]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 128
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'item': ['item_id', 'genre', 'release_year'], 'user': ['user_id', 'gender', 'age', 'occupation']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = True
enable_scaler = False
transform = None
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.2
attn_dropout_prob = 0.2
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
embedding_size = 64
pooling_mode = sum
selected_item_features = ['release_year']
selected_user_features = ['age']
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 100}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 100}


/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  df[field].fillna(value="", inplace=True)
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.
  split_point = np.cumsum(feat[field].agg(len))[:-1]
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  feat[field].fillna(value=0, inplace=True)
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  feat[field].fillna(value=feat[field].mean(), inplace=True)
05 Jun 21:06    INFO  ml-1m
The number of users: 6041
Average actions of users: 165.5975165562914
The number of items: 3884
Average actions of items: 269.88909875876953
The number of inters: 1000209
The sparsity of the dataset: 95.73712398848173%
Remain Fields: ['user_id', 'item_id', 'timestamp', 'age', 'gender', 'occupation', 'release_year', 'genre']
05 Jun 21:06    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
05 Jun 21:06    INFO  [Evaluation]: eval_batch_size = [128] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni100', 'test': 'uni100'}}]
05 Jun 21:06    INFO  SASRec(
  (item_embedding): Embedding(3884, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.2, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.2, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.2, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.2, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 351872
05 Jun 21:06    INFO  FLOPs: 4983464.0
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
05 Jun 21:12    INFO  epoch 0 training [time: 319.42s, train loss: 46291.6380]
05 Jun 21:12    INFO  epoch 0 evaluating [time: 23.65s, valid_score: 0.593600]
05 Jun 21:12    INFO  valid result: 
ndcg@10 : 0.5936    mrr@10 : 0.5242    hit@10 : 0.8121
05 Jun 21:12    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:18    INFO  epoch 1 training [time: 319.60s, train loss: 42471.3210]
05 Jun 21:18    INFO  epoch 1 evaluating [time: 23.62s, valid_score: 0.612700]
05 Jun 21:18    INFO  valid result: 
ndcg@10 : 0.6127    mrr@10 : 0.5452    hit@10 : 0.8245
05 Jun 21:18    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:23    INFO  epoch 2 training [time: 318.47s, train loss: 41769.4375]
05 Jun 21:24    INFO  epoch 2 evaluating [time: 23.63s, valid_score: 0.624100]
05 Jun 21:24    INFO  valid result: 
ndcg@10 : 0.6241    mrr@10 : 0.5591    hit@10 : 0.8281
05 Jun 21:24    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:29    INFO  epoch 3 training [time: 319.13s, train loss: 41370.0914]
05 Jun 21:29    INFO  epoch 3 evaluating [time: 23.61s, valid_score: 0.624900]
05 Jun 21:29    INFO  valid result: 
ndcg@10 : 0.6249    mrr@10 : 0.5596    hit@10 : 0.83
05 Jun 21:29    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:35    INFO  epoch 4 training [time: 317.96s, train loss: 41079.9401]
05 Jun 21:35    INFO  epoch 4 evaluating [time: 23.59s, valid_score: 0.630700]
05 Jun 21:35    INFO  valid result: 
ndcg@10 : 0.6307    mrr@10 : 0.5656    hit@10 : 0.8344
05 Jun 21:35    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:40    INFO  epoch 5 training [time: 317.57s, train loss: 40866.8668]
05 Jun 21:41    INFO  epoch 5 evaluating [time: 23.61s, valid_score: 0.630900]
05 Jun 21:41    INFO  valid result: 
ndcg@10 : 0.6309    mrr@10 : 0.5667    hit@10 : 0.8325
05 Jun 21:41    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:46    INFO  epoch 6 training [time: 318.43s, train loss: 40702.9127]
05 Jun 21:46    INFO  epoch 6 evaluating [time: 23.59s, valid_score: 0.632400]
05 Jun 21:46    INFO  valid result: 
ndcg@10 : 0.6324    mrr@10 : 0.5673    hit@10 : 0.8363
05 Jun 21:46    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:52    INFO  epoch 7 training [time: 317.71s, train loss: 40569.1066]
05 Jun 21:52    INFO  epoch 7 evaluating [time: 23.55s, valid_score: 0.641900]
05 Jun 21:52    INFO  valid result: 
ndcg@10 : 0.6419    mrr@10 : 0.5792    hit@10 : 0.8386
05 Jun 21:52    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 21:57    INFO  epoch 8 training [time: 317.31s, train loss: 40454.5109]
05 Jun 21:58    INFO  epoch 8 evaluating [time: 23.54s, valid_score: 0.632600]
05 Jun 21:58    INFO  valid result: 
ndcg@10 : 0.6326    mrr@10 : 0.5687    hit@10 : 0.8325
05 Jun 22:03    INFO  epoch 9 training [time: 316.45s, train loss: 40371.1481]
05 Jun 22:03    INFO  epoch 9 evaluating [time: 23.52s, valid_score: 0.636100]
05 Jun 22:03    INFO  valid result: 
ndcg@10 : 0.6361    mrr@10 : 0.5716    hit@10 : 0.8382
05 Jun 22:09    INFO  epoch 10 training [time: 315.41s, train loss: 40286.8870]
05 Jun 22:09    INFO  epoch 10 evaluating [time: 23.52s, valid_score: 0.638600]
05 Jun 22:09    INFO  valid result: 
ndcg@10 : 0.6386    mrr@10 : 0.5757    hit@10 : 0.8356
05 Jun 22:14    INFO  epoch 11 training [time: 314.94s, train loss: 40231.2946]
05 Jun 22:15    INFO  epoch 11 evaluating [time: 23.49s, valid_score: 0.634700]
05 Jun 22:15    INFO  valid result: 
ndcg@10 : 0.6347    mrr@10 : 0.5692    hit@10 : 0.8396
05 Jun 22:20    INFO  epoch 12 training [time: 317.12s, train loss: 40160.2082]
05 Jun 22:20    INFO  epoch 12 evaluating [time: 23.56s, valid_score: 0.638300]
05 Jun 22:20    INFO  valid result: 
ndcg@10 : 0.6383    mrr@10 : 0.5733    hit@10 : 0.8414
05 Jun 22:26    INFO  epoch 13 training [time: 317.27s, train loss: 40115.8601]
05 Jun 22:26    INFO  epoch 13 evaluating [time: 23.55s, valid_score: 0.637200]
05 Jun 22:26    INFO  valid result: 
ndcg@10 : 0.6372    mrr@10 : 0.5729    hit@10 : 0.8386
05 Jun 22:31    INFO  epoch 14 training [time: 316.61s, train loss: 40073.0650]
05 Jun 22:32    INFO  epoch 14 evaluating [time: 23.50s, valid_score: 0.641900]
05 Jun 22:32    INFO  valid result: 
ndcg@10 : 0.6419    mrr@10 : 0.5793    hit@10 : 0.8379
05 Jun 22:32    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 22:37    INFO  epoch 15 training [time: 316.33s, train loss: 40029.6709]
05 Jun 22:37    INFO  epoch 15 evaluating [time: 23.53s, valid_score: 0.642600]
05 Jun 22:37    INFO  valid result: 
ndcg@10 : 0.6426    mrr@10 : 0.5803    hit@10 : 0.8379
05 Jun 22:37    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 22:43    INFO  epoch 16 training [time: 313.32s, train loss: 39989.8144]
05 Jun 22:43    INFO  epoch 16 evaluating [time: 23.45s, valid_score: 0.640700]
05 Jun 22:43    INFO  valid result: 
ndcg@10 : 0.6407    mrr@10 : 0.5772    hit@10 : 0.8397
05 Jun 22:48    INFO  epoch 17 training [time: 293.75s, train loss: 39955.2539]
05 Jun 22:48    INFO  epoch 17 evaluating [time: 23.49s, valid_score: 0.638500]
05 Jun 22:48    INFO  valid result: 
ndcg@10 : 0.6385    mrr@10 : 0.5749    hit@10 : 0.8371
05 Jun 22:53    INFO  epoch 18 training [time: 296.85s, train loss: 39923.3313]
05 Jun 22:54    INFO  epoch 18 evaluating [time: 23.55s, valid_score: 0.640700]
05 Jun 22:54    INFO  valid result: 
ndcg@10 : 0.6407    mrr@10 : 0.5778    hit@10 : 0.8373
05 Jun 22:59    INFO  epoch 19 training [time: 298.21s, train loss: 39901.0707]
05 Jun 22:59    INFO  epoch 19 evaluating [time: 23.56s, valid_score: 0.641900]
05 Jun 22:59    INFO  valid result: 
ndcg@10 : 0.6419    mrr@10 : 0.5788    hit@10 : 0.8397
05 Jun 23:04    INFO  epoch 20 training [time: 297.92s, train loss: 39872.8574]
05 Jun 23:04    INFO  epoch 20 evaluating [time: 23.53s, valid_score: 0.637300]
05 Jun 23:04    INFO  valid result: 
ndcg@10 : 0.6373    mrr@10 : 0.5727    hit@10 : 0.8396
05 Jun 23:09    INFO  epoch 21 training [time: 297.55s, train loss: 39846.0176]
05 Jun 23:10    INFO  epoch 21 evaluating [time: 23.53s, valid_score: 0.639300]
05 Jun 23:10    INFO  valid result: 
ndcg@10 : 0.6393    mrr@10 : 0.5764    hit@10 : 0.8366
05 Jun 23:15    INFO  epoch 22 training [time: 296.15s, train loss: 39808.7667]
05 Jun 23:15    INFO  epoch 22 evaluating [time: 23.49s, valid_score: 0.640000]
05 Jun 23:15    INFO  valid result: 
ndcg@10 : 0.64    mrr@10 : 0.577    hit@10 : 0.8371
05 Jun 23:20    INFO  epoch 23 training [time: 296.28s, train loss: 39780.5431]
05 Jun 23:20    INFO  epoch 23 evaluating [time: 23.50s, valid_score: 0.642900]
05 Jun 23:20    INFO  valid result: 
ndcg@10 : 0.6429    mrr@10 : 0.5805    hit@10 : 0.8386
05 Jun 23:20    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 23:25    INFO  epoch 24 training [time: 294.86s, train loss: 39756.5835]
05 Jun 23:26    INFO  epoch 24 evaluating [time: 23.60s, valid_score: 0.643800]
05 Jun 23:26    INFO  valid result: 
ndcg@10 : 0.6438    mrr@10 : 0.5815    hit@10 : 0.8389
05 Jun 23:26    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
05 Jun 23:31    INFO  epoch 25 training [time: 297.82s, train loss: 39731.6906]
05 Jun 23:31    INFO  epoch 25 evaluating [time: 23.54s, valid_score: 0.642600]
05 Jun 23:31    INFO  valid result: 
ndcg@10 : 0.6426    mrr@10 : 0.5807    hit@10 : 0.8359
05 Jun 23:36    INFO  epoch 26 training [time: 298.04s, train loss: 39716.7852]
05 Jun 23:36    INFO  epoch 26 evaluating [time: 23.54s, valid_score: 0.641500]
05 Jun 23:36    INFO  valid result: 
ndcg@10 : 0.6415    mrr@10 : 0.5783    hit@10 : 0.8396
05 Jun 23:41    INFO  epoch 27 training [time: 297.17s, train loss: 39691.5416]
05 Jun 23:42    INFO  epoch 27 evaluating [time: 23.54s, valid_score: 0.641900]
05 Jun 23:42    INFO  valid result: 
ndcg@10 : 0.6419    mrr@10 : 0.5797    hit@10 : 0.8373
05 Jun 23:47    INFO  epoch 28 training [time: 296.85s, train loss: 39664.1010]
05 Jun 23:47    INFO  epoch 28 evaluating [time: 23.51s, valid_score: 0.643000]
05 Jun 23:47    INFO  valid result: 
ndcg@10 : 0.643    mrr@10 : 0.5802    hit@10 : 0.8391
05 Jun 23:52    INFO  epoch 29 training [time: 297.07s, train loss: 39652.2964]
05 Jun 23:52    INFO  epoch 29 evaluating [time: 23.52s, valid_score: 0.641900]
05 Jun 23:52    INFO  valid result: 
ndcg@10 : 0.6419    mrr@10 : 0.5797    hit@10 : 0.8363
05 Jun 23:57    INFO  epoch 30 training [time: 294.72s, train loss: 39625.0901]
05 Jun 23:58    INFO  epoch 30 evaluating [time: 23.52s, valid_score: 0.643500]
05 Jun 23:58    INFO  valid result: 
ndcg@10 : 0.6435    mrr@10 : 0.5811    hit@10 : 0.8397
06 Jun 00:03    INFO  epoch 31 training [time: 297.12s, train loss: 39628.3637]
06 Jun 00:03    INFO  epoch 31 evaluating [time: 23.53s, valid_score: 0.644200]
06 Jun 00:03    INFO  valid result: 
ndcg@10 : 0.6442    mrr@10 : 0.5817    hit@10 : 0.8392
06 Jun 00:03    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
06 Jun 00:08    INFO  epoch 32 training [time: 297.87s, train loss: 39595.7988]
06 Jun 00:09    INFO  epoch 32 evaluating [time: 23.54s, valid_score: 0.641600]
06 Jun 00:09    INFO  valid result: 
ndcg@10 : 0.6416    mrr@10 : 0.5794    hit@10 : 0.8366
06 Jun 00:13    INFO  epoch 33 training [time: 297.99s, train loss: 39588.9928]
06 Jun 00:14    INFO  epoch 33 evaluating [time: 23.54s, valid_score: 0.648200]
06 Jun 00:14    INFO  valid result: 
ndcg@10 : 0.6482    mrr@10 : 0.5865    hit@10 : 0.8414
06 Jun 00:14    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
06 Jun 00:19    INFO  epoch 34 training [time: 297.74s, train loss: 39569.0560]
06 Jun 00:19    INFO  epoch 34 evaluating [time: 23.52s, valid_score: 0.644300]
06 Jun 00:19    INFO  valid result: 
ndcg@10 : 0.6443    mrr@10 : 0.582    hit@10 : 0.8402
06 Jun 00:24    INFO  epoch 35 training [time: 296.84s, train loss: 39562.2249]
06 Jun 00:25    INFO  epoch 35 evaluating [time: 23.52s, valid_score: 0.643800]
06 Jun 00:25    INFO  valid result: 
ndcg@10 : 0.6438    mrr@10 : 0.5831    hit@10 : 0.8339
06 Jun 00:29    INFO  epoch 36 training [time: 295.12s, train loss: 39542.0749]
06 Jun 00:30    INFO  epoch 36 evaluating [time: 23.51s, valid_score: 0.646200]
06 Jun 00:30    INFO  valid result: 
ndcg@10 : 0.6462    mrr@10 : 0.5845    hit@10 : 0.8396
06 Jun 00:35    INFO  epoch 37 training [time: 295.34s, train loss: 39537.8220]
06 Jun 00:35    INFO  epoch 37 evaluating [time: 23.59s, valid_score: 0.649100]
06 Jun 00:35    INFO  valid result: 
ndcg@10 : 0.6491    mrr@10 : 0.5885    hit@10 : 0.8387
06 Jun 00:35    INFO  Saving current: saved/SASRec-Jun-05-2025_21-06-58.pth
06 Jun 00:40    INFO  epoch 38 training [time: 296.78s, train loss: 39536.1086]
06 Jun 00:41    INFO  epoch 38 evaluating [time: 23.55s, valid_score: 0.647800]
06 Jun 00:41    INFO  valid result: 
ndcg@10 : 0.6478    mrr@10 : 0.5858    hit@10 : 0.8419
06 Jun 00:45    INFO  epoch 39 training [time: 298.39s, train loss: 39507.0897]
06 Jun 00:46    INFO  epoch 39 evaluating [time: 23.55s, valid_score: 0.640900]
06 Jun 00:46    INFO  valid result: 
ndcg@10 : 0.6409    mrr@10 : 0.5772    hit@10 : 0.8404
06 Jun 00:51    INFO  epoch 40 training [time: 297.58s, train loss: 39501.8061]
06 Jun 00:51    INFO  epoch 40 evaluating [time: 23.50s, valid_score: 0.646500]
06 Jun 00:51    INFO  valid result: 
ndcg@10 : 0.6465    mrr@10 : 0.5856    hit@10 : 0.8376
06 Jun 00:56    INFO  epoch 41 training [time: 297.10s, train loss: 39497.3642]
06 Jun 00:57    INFO  epoch 41 evaluating [time: 23.51s, valid_score: 0.642100]
06 Jun 00:57    INFO  valid result: 
ndcg@10 : 0.6421    mrr@10 : 0.58    hit@10 : 0.8363
06 Jun 01:02    INFO  epoch 42 training [time: 296.27s, train loss: 39492.5254]
06 Jun 01:02    INFO  epoch 42 evaluating [time: 23.50s, valid_score: 0.642600]
06 Jun 01:02    INFO  valid result: 
ndcg@10 : 0.6426    mrr@10 : 0.5802    hit@10 : 0.8382
06 Jun 01:07    INFO  epoch 43 training [time: 294.11s, train loss: 39484.5303]
06 Jun 01:07    INFO  epoch 43 evaluating [time: 23.52s, valid_score: 0.644300]
06 Jun 01:07    INFO  valid result: 
ndcg@10 : 0.6443    mrr@10 : 0.5822    hit@10 : 0.8386
06 Jun 01:12    INFO  epoch 44 training [time: 296.98s, train loss: 39471.1229]
06 Jun 01:13    INFO  epoch 44 evaluating [time: 23.54s, valid_score: 0.646400]
06 Jun 01:13    INFO  valid result: 
ndcg@10 : 0.6464    mrr@10 : 0.5851    hit@10 : 0.8384
06 Jun 01:18    INFO  epoch 45 training [time: 297.61s, train loss: 39462.1913]
06 Jun 01:18    INFO  epoch 45 evaluating [time: 23.52s, valid_score: 0.644800]
06 Jun 01:18    INFO  valid result: 
ndcg@10 : 0.6448    mrr@10 : 0.5829    hit@10 : 0.8382
06 Jun 01:23    INFO  epoch 46 training [time: 297.53s, train loss: 39451.4051]
06 Jun 01:23    INFO  epoch 46 evaluating [time: 23.52s, valid_score: 0.643000]
06 Jun 01:23    INFO  valid result: 
ndcg@10 : 0.643    mrr@10 : 0.5807    hit@10 : 0.8381
06 Jun 01:28    INFO  epoch 47 training [time: 297.22s, train loss: 39441.6884]
06 Jun 01:29    INFO  epoch 47 evaluating [time: 23.52s, valid_score: 0.643700]
06 Jun 01:29    INFO  valid result: 
ndcg@10 : 0.6437    mrr@10 : 0.5802    hit@10 : 0.8429
06 Jun 01:34    INFO  epoch 48 training [time: 296.54s, train loss: 39442.1830]
06 Jun 01:34    INFO  epoch 48 evaluating [time: 23.53s, valid_score: 0.643800]
06 Jun 01:34    INFO  valid result: 
ndcg@10 : 0.6438    mrr@10 : 0.5828    hit@10 : 0.8344
06 Jun 01:34    INFO  Finished training, best eval result in epoch 37
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_file, map_location=self.device)
06 Jun 01:34    INFO  Loading model structure and parameters from saved/SASRec-Jun-05-2025_21-06-58.pth
06 Jun 01:34    INFO  The running environment of this training is as follows:
+-------------+-----------------+
| Environment |      Usage      |
+=============+=================+
| CPU         |     47.30 %     |
+-------------+-----------------+
| GPU         |  0.12 G/9.50 G  |
+-------------+-----------------+
| Memory      | 2.89 G/503.00 G |
+-------------+-----------------+
06 Jun 01:34    INFO  best valid : OrderedDict([('ndcg@10', 0.6491), ('mrr@10', 0.5885), ('hit@10', 0.8387)])
06 Jun 01:34    INFO  test result: OrderedDict([('ndcg@10', 0.6114), ('mrr@10', 0.5484), ('hit@10', 0.8096)])
