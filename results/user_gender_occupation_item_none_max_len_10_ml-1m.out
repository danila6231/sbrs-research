05 Jun 21:05    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = dataset/ml-1m-modified
checkpoint_dir = saved
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 200
train_batch_size = 128
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni100', 'test': 'uni100'}}
repeatable = True
metrics = ['NDCG', 'MRR', 'Hit']
topk = [10]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 128
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'item': ['item_id', 'genre', 'release_year'], 'user': ['user_id', 'gender', 'age', 'occupation']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 10
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = True
enable_scaler = False
transform = None
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
use_user_embedding = True
embedding_size = 64
hidden_size = 64
inner_size = 256
n_layers = 2
n_heads = 2
layer_norm_eps = 1e-12
initializer_range = 0.02
hidden_act = gelu
loss_type = CE
pooling_mode = sum
hidden_dropout_prob = 0.2
attn_dropout_prob = 0.2
selected_item_features = []
selected_user_features = ['gender', 'occupation']
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 100}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 100}


/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  feat[field].fillna(value=0, inplace=True)
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.

For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.


  feat[field].fillna(value=feat[field].mean(), inplace=True)
05 Jun 21:05    INFO  ml-1m-modified
The number of users: 6041
Average actions of users: 165.5975165562914
The number of items: 3884
Average actions of items: 269.88909875876953
The number of inters: 1000209
The sparsity of the dataset: 95.73712398848173%
Remain Fields: ['user_id', 'item_id', 'timestamp', 'age', 'gender', 'occupation', 'release_year', 'genre']
05 Jun 21:05    INFO  [Training]: train_batch_size = [128] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
05 Jun 21:05    INFO  [Evaluation]: eval_batch_size = [128] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni100', 'test': 'uni100'}}]
05 Jun 21:05    INFO  SASRecFPlus(
  (item_embedding): Embedding(3884, 64, padding_idx=0)
  (user_embedding): Embedding(6041, 64, padding_idx=0)
  (position_embedding): Embedding(11, 64)
  (feature_embed_layer): UltimateFeatureSeqEmbLayer(
    (token_embedding_table): ModuleDict(
      (user): FMEmbedding(
        (embedding): Embedding(25, 64)
      )
    )
    (float_embedding_table): ModuleDict()
    (token_seq_embedding_table): ModuleDict(
      (user): ModuleList()
      (item): ModuleList()
    )
    (float_seq_embedding_table): ModuleDict(
      (user): ModuleList()
      (item): ModuleList()
    )
  )
  (user_concat_layer): Linear(in_features=192, out_features=64, bias=True)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.2, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.2, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.2, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.2, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
Trainable parameters: 749952
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=self.enable_scaler)
05 Jun 21:07    INFO  epoch 0 training [time: 56.02s, train loss: 48301.1958]
05 Jun 21:07    INFO  epoch 0 evaluating [time: 18.27s, valid_score: 0.537500]
05 Jun 21:07    INFO  valid result: 
ndcg@10 : 0.5375    mrr@10 : 0.4623    hit@10 : 0.7758
05 Jun 21:07    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:08    INFO  epoch 1 training [time: 55.07s, train loss: 45239.6035]
05 Jun 21:08    INFO  epoch 1 evaluating [time: 18.24s, valid_score: 0.560900]
05 Jun 21:08    INFO  valid result: 
ndcg@10 : 0.5609    mrr@10 : 0.487    hit@10 : 0.794
05 Jun 21:08    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:09    INFO  epoch 2 training [time: 55.07s, train loss: 44440.8177]
05 Jun 21:09    INFO  epoch 2 evaluating [time: 18.25s, valid_score: 0.567400]
05 Jun 21:09    INFO  valid result: 
ndcg@10 : 0.5674    mrr@10 : 0.4945    hit@10 : 0.7972
05 Jun 21:09    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:10    INFO  epoch 3 training [time: 55.24s, train loss: 43890.2209]
05 Jun 21:11    INFO  epoch 3 evaluating [time: 18.26s, valid_score: 0.568400]
05 Jun 21:11    INFO  valid result: 
ndcg@10 : 0.5684    mrr@10 : 0.4956    hit@10 : 0.7987
05 Jun 21:11    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:11    INFO  epoch 4 training [time: 55.13s, train loss: 43554.1449]
05 Jun 21:12    INFO  epoch 4 evaluating [time: 18.24s, valid_score: 0.574500]
05 Jun 21:12    INFO  valid result: 
ndcg@10 : 0.5745    mrr@10 : 0.5021    hit@10 : 0.803
05 Jun 21:12    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:13    INFO  epoch 5 training [time: 55.17s, train loss: 43321.6383]
05 Jun 21:13    INFO  epoch 5 evaluating [time: 18.30s, valid_score: 0.577500]
05 Jun 21:13    INFO  valid result: 
ndcg@10 : 0.5775    mrr@10 : 0.5048    hit@10 : 0.8065
05 Jun 21:13    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:14    INFO  epoch 6 training [time: 55.05s, train loss: 43152.9837]
05 Jun 21:14    INFO  epoch 6 evaluating [time: 18.29s, valid_score: 0.582300]
05 Jun 21:14    INFO  valid result: 
ndcg@10 : 0.5823    mrr@10 : 0.5116    hit@10 : 0.805
05 Jun 21:14    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:15    INFO  epoch 7 training [time: 54.94s, train loss: 43007.9122]
05 Jun 21:15    INFO  epoch 7 evaluating [time: 18.20s, valid_score: 0.580400]
05 Jun 21:15    INFO  valid result: 
ndcg@10 : 0.5804    mrr@10 : 0.5081    hit@10 : 0.8088
05 Jun 21:16    INFO  epoch 8 training [time: 54.89s, train loss: 42882.1297]
05 Jun 21:17    INFO  epoch 8 evaluating [time: 18.23s, valid_score: 0.582100]
05 Jun 21:17    INFO  valid result: 
ndcg@10 : 0.5821    mrr@10 : 0.5108    hit@10 : 0.807
05 Jun 21:18    INFO  epoch 9 training [time: 55.08s, train loss: 42785.2544]
05 Jun 21:18    INFO  epoch 9 evaluating [time: 18.28s, valid_score: 0.582200]
05 Jun 21:18    INFO  valid result: 
ndcg@10 : 0.5822    mrr@10 : 0.5106    hit@10 : 0.8075
05 Jun 21:19    INFO  epoch 10 training [time: 55.07s, train loss: 42690.7750]
05 Jun 21:19    INFO  epoch 10 evaluating [time: 18.24s, valid_score: 0.590000]
05 Jun 21:19    INFO  valid result: 
ndcg@10 : 0.59    mrr@10 : 0.5188    hit@10 : 0.8142
05 Jun 21:19    INFO  Saving current: saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:20    INFO  epoch 11 training [time: 55.00s, train loss: 42616.9132]
05 Jun 21:20    INFO  epoch 11 evaluating [time: 18.24s, valid_score: 0.584100]
05 Jun 21:20    INFO  valid result: 
ndcg@10 : 0.5841    mrr@10 : 0.512    hit@10 : 0.8113
05 Jun 21:21    INFO  epoch 12 training [time: 55.04s, train loss: 42544.8596]
05 Jun 21:22    INFO  epoch 12 evaluating [time: 18.32s, valid_score: 0.585400]
05 Jun 21:22    INFO  valid result: 
ndcg@10 : 0.5854    mrr@10 : 0.5136    hit@10 : 0.8111
05 Jun 21:22    INFO  epoch 13 training [time: 55.15s, train loss: 42496.3110]
05 Jun 21:23    INFO  epoch 13 evaluating [time: 18.28s, valid_score: 0.585500]
05 Jun 21:23    INFO  valid result: 
ndcg@10 : 0.5855    mrr@10 : 0.5136    hit@10 : 0.8121
05 Jun 21:24    INFO  epoch 14 training [time: 55.11s, train loss: 42434.8654]
05 Jun 21:24    INFO  epoch 14 evaluating [time: 18.25s, valid_score: 0.586900]
05 Jun 21:24    INFO  valid result: 
ndcg@10 : 0.5869    mrr@10 : 0.5159    hit@10 : 0.8109
05 Jun 21:25    INFO  epoch 15 training [time: 55.02s, train loss: 42388.5528]
05 Jun 21:25    INFO  epoch 15 evaluating [time: 18.28s, valid_score: 0.588000]
05 Jun 21:25    INFO  valid result: 
ndcg@10 : 0.588    mrr@10 : 0.5166    hit@10 : 0.8136
05 Jun 21:26    INFO  epoch 16 training [time: 55.20s, train loss: 42341.9241]
05 Jun 21:26    INFO  epoch 16 evaluating [time: 18.28s, valid_score: 0.586900]
05 Jun 21:26    INFO  valid result: 
ndcg@10 : 0.5869    mrr@10 : 0.5151    hit@10 : 0.8139
05 Jun 21:27    INFO  epoch 17 training [time: 55.16s, train loss: 42312.8716]
05 Jun 21:28    INFO  epoch 17 evaluating [time: 18.23s, valid_score: 0.583300]
05 Jun 21:28    INFO  valid result: 
ndcg@10 : 0.5833    mrr@10 : 0.5102    hit@10 : 0.8136
05 Jun 21:29    INFO  epoch 18 training [time: 55.26s, train loss: 42263.0047]
05 Jun 21:29    INFO  epoch 18 evaluating [time: 18.28s, valid_score: 0.587100]
05 Jun 21:29    INFO  valid result: 
ndcg@10 : 0.5871    mrr@10 : 0.5167    hit@10 : 0.8091
05 Jun 21:30    INFO  epoch 19 training [time: 55.20s, train loss: 42234.6068]
05 Jun 21:30    INFO  epoch 19 evaluating [time: 18.27s, valid_score: 0.581700]
05 Jun 21:30    INFO  valid result: 
ndcg@10 : 0.5817    mrr@10 : 0.5093    hit@10 : 0.8098
05 Jun 21:31    INFO  epoch 20 training [time: 55.17s, train loss: 42205.8197]
05 Jun 21:31    INFO  epoch 20 evaluating [time: 18.27s, valid_score: 0.585600]
05 Jun 21:31    INFO  valid result: 
ndcg@10 : 0.5856    mrr@10 : 0.5137    hit@10 : 0.8119
05 Jun 21:32    INFO  epoch 21 training [time: 55.21s, train loss: 42178.9302]
05 Jun 21:33    INFO  epoch 21 evaluating [time: 18.30s, valid_score: 0.586100]
05 Jun 21:33    INFO  valid result: 
ndcg@10 : 0.5861    mrr@10 : 0.516    hit@10 : 0.8073
05 Jun 21:33    INFO  Finished training, best eval result in epoch 10
/gpfs/home/danila/sbrs-research/.venv/lib64/python3.9/site-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_file, map_location=self.device)
05 Jun 21:33    INFO  Loading model structure and parameters from saved/SASRecFPlus-Jun-05-2025_21-05-57.pth
05 Jun 21:33    INFO  best valid result: OrderedDict([('ndcg@10', 0.59), ('mrr@10', 0.5188), ('hit@10', 0.8142)])
05 Jun 21:33    INFO  test result: OrderedDict([('ndcg@10', 0.5564), ('mrr@10', 0.4869), ('hit@10', 0.7762)])
