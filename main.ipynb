{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.5 -q\n",
    "!pip uninstall numpy -y -q\n",
    "!pip install numpy==1.23.5 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from recbole.quick_start import run_recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 May 18:49    INFO  ['/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/ipykernel_launcher.py', '--f=/Users/danila6231/Library/Jupyter/runtime/kernel-v3c63614cec2f1861535cd785f37c8ae2de4999abc.json']\n",
      "18 May 18:49    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "n_layers = 2\n",
      "n_heads = 2\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.5\n",
      "attn_dropout_prob = 0.5\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "embedding_size = 64\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "18 May 18:49    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "18 May 18:49    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "18 May 18:49    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "18 May 18:49    INFO  SASRec(\n",
      "  (item_embedding): Embedding(1683, 64, padding_idx=0)\n",
      "  (position_embedding): Embedding(50, 64)\n",
      "  (trm_encoder): TransformerEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-1): 2 x TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 211008\n",
      "18 May 18:49    INFO  FLOPs: 4983464.0\n",
      "Train     0:   0%|                                                           | 0/20 [00:00<?, ?it/s]/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "Train     0:   5%|██▌                                                | 1/20 [00:08<02:46,  8.76s/it]:  10%|█████                                              | 2/20 [00:16<02:26,  8.15s/it]:  15%|███████▋                                           | 3/20 [00:23<02:12,  7.80s/it]:  20%|██████████▏                                        | 4/20 [00:31<02:03,  7.74s/it]:  25%|████████████▊                                      | 5/20 [00:39<01:54,  7.65s/it]:  30%|███████████████▎                                   | 6/20 [00:46<01:45,  7.55s/it]:  35%|█████████████████▊                                 | 7/20 [00:53<01:38,  7.54s/it]:  40%|████████████████████▍                              | 8/20 [01:04<01:42,  8.52s/it]:  45%|██████████████████████▉                            | 9/20 [01:12<01:32,  8.41s/it]:  50%|█████████████████████████                         | 10/20 [01:21<01:26,  8.63s/it]:  55%|███████████████████████████▌                      | 11/20 [01:30<01:17,  8.58s/it]:  60%|██████████████████████████████                    | 12/20 [01:37<01:06,  8.31s/it]:  65%|████████████████████████████████▌                 | 13/20 [01:45<00:57,  8.16s/it]:  70%|███████████████████████████████████               | 14/20 [01:55<00:51,  8.51s/it]:  75%|█████████████████████████████████████▌            | 15/20 [02:07<00:48,  9.74s/it]:  80%|████████████████████████████████████████          | 16/20 [02:17<00:38,  9.62s/it]:  85%|██████████████████████████████████████████▌       | 17/20 [02:25<00:27,  9.30s/it]:  85%|██████████████████████████████████████████▌       | 17/20 [02:39<00:28,  9.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrecbole\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquick_start\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_recbole\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_recbole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSASRec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mml-100k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_file_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/quick_start/quick_start.py:148\u001b[0m, in \u001b[0;36mrun_recbole\u001b[0;34m(model, dataset, config_file_list, config_dict, saved, queue)\u001b[0m\n\u001b[1;32m    145\u001b[0m trainer \u001b[38;5;241m=\u001b[39m get_trainer(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])(config, model)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m best_valid_score, best_valid_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshow_progress\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[1;32m    153\u001b[0m test_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    154\u001b[0m     test_data, load_best_model\u001b[38;5;241m=\u001b[39msaved, show_progress\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    155\u001b[0m )\n",
      "File \u001b[0;32m~/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/trainer/trainer.py:439\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     training_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 439\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_dict[epoch_idx] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_loss, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m train_loss\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     training_end_time \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/trainer/trainer.py:261\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    257\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    258\u001b[0m         losses\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m total_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m total_loss \u001b[38;5;241m+\u001b[39m losses\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_nan(loss)\n\u001b[0;32m--> 261\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msync_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_norm:\n\u001b[1;32m    263\u001b[0m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_norm)\n",
      "File \u001b[0;32m~/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "\n",
    "run_recbole(\n",
    "    model='SASRec',\n",
    "    dataset='ml-100k',\n",
    "    config_file_list=['test.yaml']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 May 18:37    INFO  ['/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/ipykernel_launcher.py', '--f=/Users/danila6231/Library/Jupyter/runtime/kernel-v3c63614cec2f1861535cd785f37c8ae2de4999abc.json']\n",
      "18 May 18:37    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "18 May 18:37    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "18 May 18:37    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "18 May 18:37    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "18 May 18:37    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 168128\n",
      "18 May 18:37    INFO  FLOPs: 128.0\n",
      "Train     0:   0%|                                                           | 0/20 [00:00<?, ?it/s]/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "Train     0:  20%|██████████▏                                        | 4/20 [00:00<00:00, 38.88it/s]:  70%|███████████████████████████████████               | 14/20 [00:00<00:00, 70.50it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 73.13it/s]\n",
      "18 May 18:37    INFO  epoch 0 training [time: 0.29s, train loss: 13.8629]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  70%|████████████████████████████████▎             | 331/472 [00:00<00:00, 3305.54it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 3192.90it/s]\n",
      "18 May 18:37    INFO  epoch 0 evaluating [time: 0.16s, valid_score: 0.025300]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.0067    mrr@10 : 0.0253    ndcg@10 : 0.0099    hit@10 : 0.0764    precision@10 : 0.0081\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     1:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  45%|██████████████████████▉                            | 9/20 [00:00<00:00, 86.36it/s]:  90%|█████████████████████████████████████████████     | 18/20 [00:00<00:00, 62.46it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 60.68it/s]\n",
      "18 May 18:37    INFO  epoch 1 training [time: 0.34s, train loss: 13.8371]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  26%|███████████▉                                  | 122/472 [00:00<00:00, 1216.82it/s]:  63%|████████████████████████████▊                 | 296/472 [00:00<00:00, 1523.41it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1803.53it/s]\n",
      "18 May 18:37    INFO  epoch 1 evaluating [time: 0.28s, valid_score: 0.029200]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.0079    mrr@10 : 0.0292    ndcg@10 : 0.0112    hit@10 : 0.087    precision@10 : 0.0093\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     2:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  50%|█████████████████████████                         | 10/20 [00:00<00:00, 88.74it/s]:  95%|███████████████████████████████████████████████▌  | 19/20 [00:00<00:00, 77.04it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 76.36it/s]\n",
      "18 May 18:37    INFO  epoch 2 training [time: 0.27s, train loss: 13.7987]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  48%|██████████████████████                        | 226/472 [00:00<00:00, 2257.61it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2417.39it/s]\n",
      "18 May 18:37    INFO  epoch 2 evaluating [time: 0.21s, valid_score: 0.058500]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.0156    mrr@10 : 0.0585    ndcg@10 : 0.0224    hit@10 : 0.1527    precision@10 : 0.0183\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     3:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 76.92it/s]:  85%|██████████████████████████████████████████▌       | 17/20 [00:00<00:00, 79.88it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 78.23it/s]\n",
      "18 May 18:37    INFO  epoch 3 training [time: 0.26s, train loss: 13.7074]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▍                 | 292/472 [00:00<00:00, 2913.90it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2904.18it/s]\n",
      "18 May 18:37    INFO  epoch 3 evaluating [time: 0.17s, valid_score: 0.121300]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.0389    mrr@10 : 0.1213    ndcg@10 : 0.0552    hit@10 : 0.3118    precision@10 : 0.0476\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     4:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 78.49it/s]:  85%|██████████████████████████████████████████▌       | 17/20 [00:00<00:00, 79.72it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 78.72it/s]\n",
      "18 May 18:37    INFO  epoch 4 training [time: 0.26s, train loss: 13.4684]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  61%|████████████████████████████▏                 | 289/472 [00:00<00:00, 2889.42it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2868.05it/s]\n",
      "18 May 18:37    INFO  epoch 4 evaluating [time: 0.17s, valid_score: 0.187200]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.0686    mrr@10 : 0.1872    ndcg@10 : 0.0891    hit@10 : 0.4305    precision@10 : 0.0717\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     5:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 77.74it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 78.46it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.33it/s]\n",
      "18 May 18:37    INFO  epoch 5 training [time: 0.26s, train loss: 12.9277]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  59%|███████████████████████████▎                  | 280/472 [00:00<00:00, 2797.90it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2766.07it/s]\n",
      "18 May 18:37    INFO  epoch 5 evaluating [time: 0.18s, valid_score: 0.218900]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.0919    mrr@10 : 0.2189    ndcg@10 : 0.1115    hit@10 : 0.491    precision@10 : 0.0883\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     6:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  15%|███████▋                                           | 3/20 [00:00<00:00, 28.09it/s]:  55%|███████████████████████████▌                      | 11/20 [00:00<00:00, 54.13it/s]:  95%|███████████████████████████████████████████████▌  | 19/20 [00:00<00:00, 63.83it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 58.52it/s]\n",
      "18 May 18:37    INFO  epoch 6 training [time: 0.35s, train loss: 11.9466]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  60%|███████████████████████████▋                  | 284/472 [00:00<00:00, 2838.49it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2814.04it/s]\n",
      "18 May 18:37    INFO  epoch 6 evaluating [time: 0.18s, valid_score: 0.235300]\n",
      "18 May 18:37    INFO  valid result: \n",
      "recall@10 : 0.1026    mrr@10 : 0.2353    ndcg@10 : 0.1228    hit@10 : 0.5239    precision@10 : 0.0957\n",
      "18 May 18:37    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     7:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 78.28it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 78.47it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.51it/s]\n",
      "18 May 18:37    INFO  epoch 7 training [time: 0.26s, train loss: 10.6594]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  59%|███████████████████████████▎                  | 280/472 [00:00<00:00, 2793.43it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2781.87it/s]\n",
      "18 May 18:38    INFO  epoch 7 evaluating [time: 0.18s, valid_score: 0.257500]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1095    mrr@10 : 0.2575    ndcg@10 : 0.133    hit@10 : 0.5451    precision@10 : 0.1003\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     8:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 76.69it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 78.24it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.42it/s]\n",
      "18 May 18:38    INFO  epoch 8 training [time: 0.26s, train loss: 9.3435]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▎                 | 291/472 [00:00<00:00, 2900.19it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2895.47it/s]\n",
      "18 May 18:38    INFO  epoch 8 evaluating [time: 0.17s, valid_score: 0.273500]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1226    mrr@10 : 0.2735    ndcg@10 : 0.1429    hit@10 : 0.5737    precision@10 : 0.1048\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train     9:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 77.88it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 78.46it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.39it/s]\n",
      "18 May 18:38    INFO  epoch 9 training [time: 0.26s, train loss: 8.2992]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  61%|████████████████████████████▎                 | 290/472 [00:00<00:00, 2898.55it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2829.59it/s]\n",
      "18 May 18:38    INFO  epoch 9 evaluating [time: 0.18s, valid_score: 0.282200]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1253    mrr@10 : 0.2822    ndcg@10 : 0.1473    hit@10 : 0.5779    precision@10 : 0.1055\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    10:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 76.99it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 77.20it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 74.16it/s]\n",
      "18 May 18:38    INFO  epoch 10 training [time: 0.27s, train loss: 7.6039]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  60%|███████████████████████████▌                  | 283/472 [00:00<00:00, 2827.23it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2770.10it/s]\n",
      "18 May 18:38    INFO  epoch 10 evaluating [time: 0.18s, valid_score: 0.291000]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1315    mrr@10 : 0.291    ndcg@10 : 0.1524    hit@10 : 0.596    precision@10 : 0.106\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    11:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 77.75it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 79.04it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.77it/s]\n",
      "18 May 18:38    INFO  epoch 11 training [time: 0.26s, train loss: 7.1607]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▊                 | 295/472 [00:00<00:00, 2943.74it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2915.16it/s]\n",
      "18 May 18:38    INFO  epoch 11 evaluating [time: 0.17s, valid_score: 0.295600]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1335    mrr@10 : 0.2956    ndcg@10 : 0.1549    hit@10 : 0.5949    precision@10 : 0.1076\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    12:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 77.59it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 78.53it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.65it/s]\n",
      "18 May 18:38    INFO  epoch 12 training [time: 0.26s, train loss: 6.8321]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  25%|███████████▋                                  | 120/472 [00:00<00:00, 1198.81it/s]:  83%|██████████████████████████████████████        | 391/472 [00:00<00:00, 2086.57it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2055.23it/s]\n",
      "18 May 18:38    INFO  epoch 12 evaluating [time: 0.24s, valid_score: 0.295700]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1341    mrr@10 : 0.2957    ndcg@10 : 0.1562    hit@10 : 0.5938    precision@10 : 0.1077\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    13:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  45%|██████████████████████▉                            | 9/20 [00:00<00:00, 84.55it/s]:  90%|█████████████████████████████████████████████     | 18/20 [00:00<00:00, 84.32it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 81.85it/s]\n",
      "18 May 18:38    INFO  epoch 13 training [time: 0.25s, train loss: 6.6535]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  60%|███████████████████████████▊                  | 285/472 [00:00<00:00, 2842.32it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2823.40it/s]\n",
      "18 May 18:38    INFO  epoch 13 evaluating [time: 0.18s, valid_score: 0.302100]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1381    mrr@10 : 0.3021    ndcg@10 : 0.1602    hit@10 : 0.6076    precision@10 : 0.1099\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    14:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 78.19it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 79.20it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 78.61it/s]\n",
      "18 May 18:38    INFO  epoch 14 training [time: 0.26s, train loss: 6.4700]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▎                 | 291/472 [00:00<00:00, 2907.79it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2697.18it/s]\n",
      "18 May 18:38    INFO  epoch 14 evaluating [time: 0.19s, valid_score: 0.302400]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1424    mrr@10 : 0.3024    ndcg@10 : 0.1625    hit@10 : 0.6129    precision@10 : 0.111\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    15:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 78.46it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 78.83it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.70it/s]\n",
      "18 May 18:38    INFO  epoch 15 training [time: 0.26s, train loss: 6.2722]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▍                 | 292/472 [00:00<00:00, 2910.95it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2852.26it/s]\n",
      "18 May 18:38    INFO  epoch 15 evaluating [time: 0.18s, valid_score: 0.307100]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1449    mrr@10 : 0.3071    ndcg@10 : 0.1653    hit@10 : 0.6225    precision@10 : 0.1123\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    16:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 78.24it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 79.20it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.74it/s]\n",
      "18 May 18:38    INFO  epoch 16 training [time: 0.26s, train loss: 6.1586]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  61%|████████████████████████████▏                 | 289/472 [00:00<00:00, 2886.86it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2862.32it/s]\n",
      "18 May 18:38    INFO  epoch 16 evaluating [time: 0.17s, valid_score: 0.313700]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1484    mrr@10 : 0.3137    ndcg@10 : 0.1693    hit@10 : 0.6267    precision@10 : 0.1141\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "Train    17:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 79.07it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 79.38it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 78.42it/s]\n",
      "18 May 18:38    INFO  epoch 17 training [time: 0.26s, train loss: 5.9534]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  61%|███████████████████████████▉                  | 287/472 [00:00<00:00, 2863.47it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2824.10it/s]\n",
      "18 May 18:38    INFO  epoch 17 evaluating [time: 0.18s, valid_score: 0.312700]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1507    mrr@10 : 0.3127    ndcg@10 : 0.171    hit@10 : 0.631    precision@10 : 0.1166\n",
      "Train    18:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  20%|██████████▏                                        | 4/20 [00:00<00:00, 37.00it/s]:  60%|██████████████████████████████                    | 12/20 [00:00<00:00, 59.49it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 66.79it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 62.07it/s]\n",
      "18 May 18:38    INFO  epoch 18 training [time: 0.33s, train loss: 5.8684]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▌                 | 293/472 [00:00<00:00, 2921.64it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2872.97it/s]\n",
      "18 May 18:38    INFO  epoch 18 evaluating [time: 0.18s, valid_score: 0.312500]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1553    mrr@10 : 0.3125    ndcg@10 : 0.1741    hit@10 : 0.6405    precision@10 : 0.12\n",
      "Train    19:   0%|                                                           | 0/20 [00:00<?, ?it/s]:  40%|████████████████████▍                              | 8/20 [00:00<00:00, 77.93it/s]:  80%|████████████████████████████████████████          | 16/20 [00:00<00:00, 75.64it/s]: 100%|██████████████████████████████████████████████████| 20/20 [00:00<00:00, 75.52it/s]\n",
      "18 May 18:38    INFO  epoch 19 training [time: 0.27s, train loss: 5.7833]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▌                 | 293/472 [00:00<00:00, 2920.74it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2809.02it/s]\n",
      "18 May 18:38    INFO  epoch 19 evaluating [time: 0.18s, valid_score: 0.318900]\n",
      "18 May 18:38    INFO  valid result: \n",
      "recall@10 : 0.1577    mrr@10 : 0.3189    ndcg@10 : 0.1779    hit@10 : 0.6437    precision@10 : 0.1221\n",
      "18 May 18:38    INFO  Saving current: saved/BPR-May-18-2025_18-37-55.pth\n",
      "/Users/danila6231/Cursor/sbrs-research/.venv/lib/python3.9/site-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "18 May 18:38    INFO  Loading model structure and parameters from saved/BPR-May-18-2025_18-37-55.pth\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  62%|████████████████████████████▍                 | 292/472 [00:00<00:00, 2917.55it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 2871.73it/s]\n",
      "18 May 18:38    INFO  The running environment of this training is as follows:\n",
      "+-------------+---------------+\n",
      "| Environment |     Usage     |\n",
      "+=============+===============+\n",
      "| CPU         |    16.70 %    |\n",
      "+-------------+---------------+\n",
      "| GPU         |   0.0 / 0.0   |\n",
      "+-------------+---------------+\n",
      "| Memory      | 0.48 G/8.00 G |\n",
      "+-------------+---------------+\n",
      "18 May 18:38    INFO  best valid : OrderedDict([('recall@10', 0.1577), ('mrr@10', 0.3189), ('ndcg@10', 0.1779), ('hit@10', 0.6437), ('precision@10', 0.1221)])\n",
      "18 May 18:38    INFO  test result: OrderedDict([('recall@10', 0.1784), ('mrr@10', 0.3929), ('ndcg@10', 0.2182), ('hit@10', 0.6734), ('precision@10', 0.1445)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_valid_score': 0.3189,\n",
       " 'valid_score_bigger': True,\n",
       " 'best_valid_result': OrderedDict([('recall@10', 0.1577),\n",
       "              ('mrr@10', 0.3189),\n",
       "              ('ndcg@10', 0.1779),\n",
       "              ('hit@10', 0.6437),\n",
       "              ('precision@10', 0.1221)]),\n",
       " 'test_result': OrderedDict([('recall@10', 0.1784),\n",
       "              ('mrr@10', 0.3929),\n",
       "              ('ndcg@10', 0.2182),\n",
       "              ('hit@10', 0.6734),\n",
       "              ('precision@10', 0.1445)])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res =run_recbole(model='BPR', dataset='ml-100k', config_file_list=['test.yaml'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
